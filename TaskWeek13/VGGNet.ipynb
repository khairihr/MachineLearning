{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOlNWM4WcUXBYWe7gF87sR8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khairihr/MachineLearning/blob/main/TaskWeek13/VGGNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nama: Khairi Hibatullah Ridho\n",
        "\n",
        "NIM: 1103228240\n",
        "\n",
        "https://poloclub.github.io/cnn-explainer/\n",
        "\n",
        "https://convnetplayground.fastforwardlabs.com/#/\n",
        "\n",
        "LeNet-5, AlexNet and VGGNet.\n",
        "\n",
        "https://landing.ai/ https://www.ultralytics.com/"
      ],
      "metadata": {
        "id": "Xufcnw7MrNN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##VGGNet"
      ],
      "metadata": {
        "id": "lVGqYqwWrPo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGGNet (Visual Geometry Group Network) adalah salah satu arsitektur jaringan saraf tiruan konvolusi (CNN) yang sangat terkenal dalam pengenalan gambar dan komputer visi. Arsitektur ini dikembangkan oleh tim peneliti dari Visual Geometry Group di Universitas Oxford pada tahun 2014. VGGNet dikenal karena kekonsistensiannya dalam desain, dengan struktur yang dalam dan mendalam, yang menjadi referensi dalam pengembangan arsitektur CNN yang lebih kompleks.\n",
        "\n",
        "Berikut adalah beberapa karakteristik utama dari arsitektur VGGNet:\n",
        "\n",
        "1. **Kedalaman yang Dalam**: Salah satu ciri utama VGGNet adalah kedalaman arsitekturnya. Arsitektur ini terdiri dari beberapa lapisan konvolusi (Convolutional layers) yang dalam. Terdapat dua varian utama dari VGGNet: VGG16, yang memiliki 16 lapisan (13 lapisan konvolusi dan 3 lapisan Fully Connected), dan VGG19, yang memiliki 19 lapisan (16 lapisan konvolusi dan 3 lapisan Fully Connected). Kedalaman ini membantu dalam ekstraksi fitur hierarkis yang lebih kompleks dari gambar.\n",
        "\n",
        "2. **Ukuran Kernel Konstan**: VGGNet menggunakan kernel konvolusi berukuran kecil (biasanya 3x3 piksel) dengan langkah (stride) 1 dan padding 1 untuk semua lapisan konvolusi. Hal ini menghasilkan operasi konvolusi yang kecil dan seragam, yang membantu dalam pemahaman fitur pada berbagai skala.\n",
        "\n",
        "3. **Max-Pooling**: Setelah beberapa lapisan konvolusi, VGGNet menggunakan max-pooling dengan ukuran filter 2x2 piksel dan langkah 2x2 piksel untuk mengurangi dimensi gambar. Ini membantu dalam mengurangi overfitting dan menghasilkan representasi fitur yang lebih kecil.\n",
        "\n",
        "4. **Fully Connected Layers**: Setelah lapisan-lapisan konvolusi dan max-pooling, VGGNet memiliki beberapa lapisan Fully Connected (FC) yang diikuti oleh fungsi aktivasi ReLU. Lapisan FC ini digunakan untuk menggabungkan fitur-fitur yang telah diekstraksi sebelumnya untuk klasifikasi.\n",
        "\n",
        "5. **Fungsi Aktivasi ReLU**: ReLU (Rectified Linear Unit) digunakan sebagai fungsi aktivasi di seluruh arsitektur VGGNet. Ini memberikan non-linearitas ke jaringan dan membantu mengatasi masalah vanishng gradient yang umum terjadi dalam jaringan yang dalam.\n",
        "\n",
        "6. **Klasifikasi Multi-Kelas**: VGGNet biasanya digunakan untuk tugas klasifikasi multi-kelas, seperti mengenali objek dalam gambar pada dataset ImageNet, di mana terdapat ribuan kelas berbeda.\n",
        "\n",
        "Arsitektur VGGNet telah menjadi dasar bagi pengembangan banyak arsitektur CNN yang lebih kompleks, termasuk ResNet, Inception, dan lainnya. Meskipun VGGNet memiliki banyak parameter, ia terkenal karena kemampuannya dalam menghasilkan representasi fitur yang kuat, meskipun dengan biaya komputasi yang tinggi."
      ],
      "metadata": {
        "id": "9B8l0eHPrT4p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSDMHOJ9rLn0",
        "outputId": "4e3c8320-45b5-4bf3-da9c-639c5a122276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 156962923.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 38763422.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 36940115.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 13415865.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Epoch 1/5, Loss: 0.21509855238299794\n",
            "Epoch 2/5, Loss: 0.06588682752374074\n",
            "Epoch 3/5, Loss: 0.05543005707881799\n",
            "Epoch 4/5, Loss: 0.04790577211272731\n",
            "Epoch 5/5, Loss: 0.040858554438265374\n",
            "Test Accuracy: 0.9883\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set device to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the VGGNet architecture for MNIST\n",
        "class VGGNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGGNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 7 * 7, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 10),  # 10 classes for MNIST\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Load MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = VGGNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "# Testing\n",
        "model.eval()\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "        total_correct += (predictions == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "accuracy = total_correct / total_samples\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Berikut adalah penjelasan langkah demi langkah dari kode tersebut:\n",
        "\n",
        "1. **Impor Library**: Kode dimulai dengan mengimpor beberapa pustaka PyTorch yang diperlukan, termasuk `torch`, `torch.nn`, `torch.optim`, `torchvision`, `transforms`, dan `DataLoader`. Ini termasuk pengaturan perangkat (CPU atau GPU) yang akan digunakan untuk pelatihan.\n",
        "\n",
        "2. **Definisi Arsitektur VGGNet**: Anda mendefinisikan arsitektur VGGNet dalam kelas `VGGNet`. Arsitektur ini mencakup lapisan-lapisan konvolusi, ReLU, max-pooling, dan lapisan-lapisan linear untuk klasifikasi. Anda menggunakan `nn.Sequential` untuk mengelompokkan lapisan-lapisan konvolusi dan aktivasi.\n",
        "\n",
        "3. **Transformasi Data**: Anda mendefinisikan transformasi data untuk dataset MNIST. Ini termasuk mengubah gambar menjadi tensor dan menyesuaikan ukuran gambar menjadi 28x28 piksel.\n",
        "\n",
        "4. **Memuat Dataset**: Anda memuat dataset MNIST menggunakan `torchvision.datasets.MNIST`. Ini akan mengunduh dataset jika belum ada di direktori yang ditentukan. Selanjutnya, Anda membuat dua objek `DataLoader` untuk data pelatihan dan pengujian. DataLoader digunakan untuk memecah data menjadi batch-batch yang dapat digunakan untuk pelatihan dan pengujian model.\n",
        "\n",
        "5. **Inisialisasi Model, Fungsi Loss, dan Optimizer**: Anda membuat objek model `VGGNet`, memilih fungsi loss `nn.CrossEntropyLoss()` untuk tugas klasifikasi, dan memilih optimizer `optim.Adam` dengan learning rate 0.001.\n",
        "\n",
        "6. **Pelatihan**: Anda melakukan pelatihan model menggunakan loop `for` yang berjalan sebanyak `num_epochs`. Dalam loop pelatihan, Anda mengirimkan batch data ke model, menghitung loss, melakukan backpropagation, dan memperbarui bobot model melalui optimizer. Setiap epoch mencatat loss rata-rata selama iterasi pelatihan dan mencetaknya.\n",
        "\n",
        "7. **Pengujian**: Setelah pelatihan selesai, Anda melakukan pengujian model pada dataset pengujian. Model dinilai pada mode evaluasi dengan menggunakan `model.eval()`. Anda menghitung jumlah prediksi yang benar dan total sampel untuk mengukur akurasi pengujian.\n",
        "\n",
        "8. **Akurasi Pengujian**: Akurasi pengujian dihitung dengan membagi jumlah prediksi yang benar dengan total sampel dan dicetak.\n",
        "\n",
        "Kode ini akan melatih model VGGNet untuk mengenali digit dalam dataset MNIST dan mencetak akurasi pengujian setelah pelatihan selesai. Meskipun VGGNet biasanya digunakan untuk dataset gambar dengan resolusi lebih tinggi, Anda telah mengadaptasinya untuk dataset MNIST dengan mengubah arsitektur dan ukuran gambar."
      ],
      "metadata": {
        "id": "I5jD1sL3rvfr"
      }
    }
  ]
}
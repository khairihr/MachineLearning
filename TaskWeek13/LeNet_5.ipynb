{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP9CG8+8NAbJT0QbRs0iHrt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khairihr/MachineLearning/blob/main/TaskWeek13/LeNet_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nama: Khairi Hibatullah Ridho\n",
        "\n",
        "NIM: 1103228240\n",
        "\n",
        "https://poloclub.github.io/cnn-explainer/\n",
        "\n",
        "https://convnetplayground.fastforwardlabs.com/#/\n",
        "\n",
        "LeNet-5, AlexNet and VGGNet.\n",
        "\n",
        "https://landing.ai/ https://www.ultralytics.com/"
      ],
      "metadata": {
        "id": "GKbwf7Okpkhr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LeNet 5"
      ],
      "metadata": {
        "id": "vY0qPSc6ps4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LeNet-5 adalah salah satu arsitektur jaringan saraf tiruan konvolusi (convolutional neural network atau CNN) yang dikembangkan oleh Yann LeCun, Leon Bottou, Yoshua Bengio, dan Patrick Haffner pada tahun 1998. LeNet-5 adalah salah satu model CNN pertama yang digunakan secara luas untuk mengenali karakter tulisan tangan dalam aplikasi pengenalan tulisan tangan, seperti pengenalan angka pada cek dan kode pos pada amplop.\n",
        "\n",
        "Arsitektur LeNet-5 memiliki beberapa ciri khas:\n",
        "\n",
        "1. Convolutional Layers: LeNet-5 menggunakan dua lapisan konvolusi (convolutional layers) yang diikuti oleh lapisan subsampling (pooling) untuk mengekstraksi fitur-fitur penting dari gambar masukan. Konvolusi adalah operasi yang digunakan untuk memproses gambar secara lokal.\n",
        "\n",
        "2. Activation Functions: Setelah setiap lapisan konvolusi dan subsampling, fungsi aktivasi seperti ReLU (Rectified Linear Unit) diterapkan untuk memperkenalkan non-linearitas ke dalam jaringan.\n",
        "\n",
        "3. Fully Connected Layers: Setelah lapisan konvolusi dan subsampling, terdapat beberapa lapisan tersembunyi (fully connected layers) yang menghubungkan semua neuron pada lapisan tersebut dengan neuron pada lapisan berikutnya. Ini digunakan untuk menggabungkan fitur-fitur yang telah diekstraksi sebelumnya.\n",
        "\n",
        "4. Softmax Layer: Lapisan output dari LeNet-5 biasanya menggunakan fungsi softmax untuk menghasilkan probabilitas prediksi kelas yang digunakan untuk klasifikasi.\n",
        "\n",
        "5. Jumlah Parameter yang Terbatas: LeNet-5 memiliki jumlah parameter yang relatif sedikit dibandingkan dengan arsitektur CNN modern saat ini, karena pada saat itu komputasi dan penyimpanan terbatas. Meskipun demikian, LeNet-5 mampu memberikan hasil yang baik dalam tugas pengenalan karakter tulisan tangan.\n",
        "\n",
        "LeNet-5 telah membuka jalan bagi perkembangan lebih lanjut dalam pengenalan gambar dan tugas-tugas komputer visi. Arsitektur ini mengilhami banyak jaringan CNN lainnya yang digunakan dalam berbagai aplikasi, termasuk pengenalan gambar, deteksi objek, dan klasifikasi gambar. LeNet-5 adalah salah satu tonggak penting dalam perkembangan deep learning dan komputer visi."
      ],
      "metadata": {
        "id": "ufIIUaltp38J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#arsitektur lenet 5:\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set device to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the LeNet-5 architecture for MNIST\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.relu4 = nn.ReLU()\n",
        "\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.relu4(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = LeNet5().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "# Testing\n",
        "model.eval()\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "        total_correct += (predictions == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "accuracy = total_correct / total_samples\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOZ_HoWvqQl1",
        "outputId": "12c4a163-76c4-4067-89c4-36cc9788b179"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 300472011.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 110023336.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 125492494.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 20418573.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Epoch 1/5, Loss: 0.2841396177195505\n",
            "Epoch 2/5, Loss: 0.08065947837956837\n",
            "Epoch 3/5, Loss: 0.05975578717072246\n",
            "Epoch 4/5, Loss: 0.04698737218170794\n",
            "Epoch 5/5, Loss: 0.03751578768352861\n",
            "Test Accuracy: 0.9903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Di bawah ini adalah penjelasan lebih rinci tentang setiap bagian dari kode tersebut:\n",
        "\n",
        "1. **Impor Library**: Kode dimulai dengan mengimpor beberapa pustaka PyTorch yang diperlukan, seperti `torch`, `torch.nn`, `torch.optim`, `torchvision`, dan `transforms`. Ini termasuk mengatur perangkat (CPU atau GPU) yang akan digunakan untuk pelatihan.\n",
        "\n",
        "2. **Definisi Arsitektur LeNet-5**: Anda mendefinisikan arsitektur LeNet-5 dalam kelas `LeNet5` menggunakan modul `nn.Module` PyTorch. Arsitektur ini mencakup dua lapisan konvolusi (`conv1` dan `conv2`), dua lapisan ReLU (`relu1` dan `relu2`), dua lapisan MaxPooling (`pool1` dan `pool2`), dan tiga lapisan linear (`fc1`, `fc2`, dan `fc3`) untuk klasifikasi. Setiap lapisan konvolusi diikuti oleh ReLU dan MaxPooling.\n",
        "\n",
        "3. **Transformasi Data**: Anda mendefinisikan transformasi data untuk dataset MNIST. Ini termasuk mengubah gambar menjadi tensor dan menyesuaikan ukuran gambar menjadi 28x28 piksel.\n",
        "\n",
        "4. **Memuat Dataset**: Anda memuat dataset MNIST menggunakan `torchvision.datasets.MNIST`. Ini akan mengunduh dataset jika belum ada di direktori yang ditentukan. Selanjutnya, Anda membuat dua objek `DataLoader` untuk data pelatihan dan pengujian. DataLoader digunakan untuk memecah data menjadi batch-batch yang dapat digunakan untuk pelatihan dan pengujian model.\n",
        "\n",
        "5. **Inisialisasi Model, Fungsi Loss, dan Optimizer**: Anda membuat objek model `LeNet5`, memilih fungsi loss `nn.CrossEntropyLoss()` untuk tugas klasifikasi, dan memilih optimizer `optim.Adam` dengan learning rate 0.001.\n",
        "\n",
        "6. **Pelatihan**: Anda melakukan pelatihan model menggunakan loop `for` yang berjalan sebanyak `num_epochs`. Dalam loop pelatihan, Anda mengirimkan batch data ke model, menghitung loss, melakukan backpropagation, dan memperbarui bobot model melalui optimizer. Setiap epoch mencatat loss rata-rata selama iterasi pelatihan dan mencetaknya.\n",
        "\n",
        "7. **Pengujian**: Setelah pelatihan selesai, Anda melakukan pengujian model pada dataset pengujian. Model dinilai pada mode evaluasi dengan menggunakan `model.eval()`. Anda menghitung jumlah prediksi yang benar dan total sampel untuk mengukur akurasi pengujian.\n",
        "\n",
        "8. **Akurasi Pengujian**: Akurasi pengujian dihitung dengan membagi jumlah prediksi yang benar dengan total sampel dan dicetak.\n",
        "\n",
        "Kode ini akan melatih model LeNet-5 untuk mengenali digit dalam dataset MNIST dan mencetak akurasi pengujian setelah pelatihan selesai. LeNet-5 adalah salah satu arsitektur klasik yang sering digunakan dalam pengenalan gambar dan sangat cocok untuk dataset seperti MNIST."
      ],
      "metadata": {
        "id": "x2uWA009q4TW"
      }
    }
  ]
}